{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection using Simulated Annealing\n",
    "\n",
    "Adapted from: https://github.com/kennethleungty/Simulated-Annealing-Feature-Selection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "\n",
    "def train_model(X, y):\n",
    "    \"\"\"\n",
    "    Run random forest classification model on feature subset\n",
    "    and retrieve cross validated ROC-AUC score\n",
    "    \"\"\"\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    kf = KFold(shuffle=True, n_splits=3, random_state=42)\n",
    "    cv_roc_auc_score = round(cross_val_score(clf, X, y.values.ravel(), cv=kf, \n",
    "                                             scoring=\"roc_auc\", n_jobs=-1).mean(), 3)\n",
    "\n",
    "    return cv_roc_auc_score\n",
    "\n",
    "OUTPUT_PATH = '../results/'\n",
    "\n",
    "# Setup simulated annealing algorithm\n",
    "def simulated_annealing(X_train,\n",
    "                        y_train,\n",
    "                        maxiters=50,\n",
    "                        alpha=0.85,\n",
    "                        beta=1,\n",
    "                        T_0=1,\n",
    "                        update_iters=1,\n",
    "                        temp_reduction='geometric'):\n",
    "    \"\"\"\n",
    "    Function to perform feature selection using simulated annealing\n",
    "    Inputs:\n",
    "    X_train: Predictor features\n",
    "    y_train: Train labels\n",
    "    maxiters: Maximum number of iterations\n",
    "    alpha: Factor to reduce temperature\n",
    "    beta: Constant in probability estimate \n",
    "    T_0: Initial temperature\n",
    "    update_iters: Number of iterations required to update temperature\n",
    "    temp_reduction: Strategy for temperature reduction schedule\n",
    "\n",
    "    Output:\n",
    "    1) Dataframe of parameters explored and corresponding model performance\n",
    "    2) Best metric score (i.e. AUC score in this case)\n",
    "    3) List of subset features that correspond to the best metric\n",
    "    \"\"\"\n",
    "    columns = ['Iteration', 'Feature Count', 'Feature Set', \n",
    "               'Metric', 'Best Metric', 'Acceptance Probability', \n",
    "               'Random Number', 'Outcome']\n",
    "    results = pd.DataFrame(index=range(maxiters), columns=columns)\n",
    "    best_subset = None\n",
    "    hash_values = set()\n",
    "    T = T_0\n",
    "\n",
    "    # Get ascending range indices of all columns\n",
    "    full_set = set(np.arange(len(X_train.columns)))\n",
    "\n",
    "    # Generate initial random subset based on ~50% of columns\n",
    "    curr_subset = set(random.sample(list(full_set), round(0.5 * len(full_set))))\n",
    "\n",
    "    # Get baseline metric score (i.e. AUC) of initial random subset\n",
    "    X_curr = X_train.iloc[:, list(curr_subset)]\n",
    "    prev_metric = train_model(X_curr, y_train)\n",
    "    best_metric = prev_metric\n",
    "\n",
    "    for i in range(maxiters):\n",
    "        # Termination conditions\n",
    "        if T < 0.01:\n",
    "            print(f'Temperature {T} below threshold. Termination condition met')\n",
    "            break\n",
    "        \n",
    "        print(f'Starting Iteration {i+1}')\n",
    "\n",
    "        # Execute pertubation (i.e. alter current subset to get new subset)\n",
    "        while True:\n",
    "            # Decide what type of pertubation to make\n",
    "            if len(curr_subset) == len(full_set): \n",
    "                move = 'Remove'\n",
    "            elif len(curr_subset) == 2: # Not to go below 2 features\n",
    "                move = random.choice(['Add', 'Replace'])\n",
    "            else:\n",
    "                move = random.choice(['Add', 'Replace', 'Remove'])\n",
    "            \n",
    "            # Get columns not yet used in current subset\n",
    "            pending_cols = full_set.difference(curr_subset) \n",
    "            new_subset = curr_subset.copy()   \n",
    "\n",
    "            if move == 'Add':        \n",
    "                new_subset.add(random.choice(list(pending_cols)))\n",
    "            elif move == 'Replace': \n",
    "                new_subset.remove(random.choice(list(curr_subset)))\n",
    "                new_subset.add(random.choice(list(pending_cols)))\n",
    "            else:\n",
    "                new_subset.remove(random.choice(list(curr_subset)))\n",
    "                \n",
    "            if new_subset in hash_values:\n",
    "                print('Subset already visited')\n",
    "            else:\n",
    "                hash_values.add(frozenset(new_subset))\n",
    "                break\n",
    "\n",
    "        # Filter dataframe to current subset\n",
    "        X_new = X_train.iloc[:, list(new_subset)]\n",
    "\n",
    "        # Get metric of new subset\n",
    "        metric = train_model(X_new, y_train)\n",
    "\n",
    "        if metric > prev_metric:\n",
    "            print('Local improvement in metric from {:8.4f} to {:8.4f} '\n",
    "                  .format(prev_metric, metric) + ' - New subset accepted')\n",
    "            outcome = 'Improved'\n",
    "            accept_prob, rnd = '-', '-'\n",
    "            prev_metric = metric\n",
    "            curr_subset = new_subset.copy()\n",
    "\n",
    "            # Keep track of overall best metric so far\n",
    "            if metric > best_metric:\n",
    "                print('Global improvement in metric from {:8.4f} to {:8.4f} '\n",
    "                      .format(best_metric, metric) + ' - Best subset updated')\n",
    "                best_metric = metric\n",
    "                best_subset = new_subset.copy()\n",
    "                \n",
    "        else:\n",
    "            rnd = np.random.uniform()\n",
    "            diff = prev_metric - metric\n",
    "            accept_prob = np.exp(-beta * diff / T)\n",
    "\n",
    "            if rnd < accept_prob:\n",
    "                print('New subset has worse performance but still accept. Metric change' +\n",
    "                      ':{:8.4f}, Acceptance probability:{:6.4f}, Random number:{:6.4f}'\n",
    "                      .format(diff, accept_prob, rnd))\n",
    "                outcome = 'Accept'\n",
    "                prev_metric = metric\n",
    "                curr_subset = new_subset.copy()\n",
    "            else:\n",
    "                print('New subset has worse performance, therefore reject. Metric change' +\n",
    "                      ':{:8.4f}, Acceptance probability:{:6.4f}, Random number:{:6.4f}'\n",
    "                      .format(diff, accept_prob, rnd))\n",
    "                outcome = 'Reject'\n",
    "\n",
    "        # Update results dataframe\n",
    "        results.loc[i, 'Iteration'] = i+1\n",
    "        results.loc[i, 'Feature Count'] = len(curr_subset)\n",
    "        results.loc[i, 'Feature Set'] = sorted(curr_subset)\n",
    "        results.loc[i, 'Metric'] = metric\n",
    "        results.loc[i, 'Best Metric'] = best_metric\n",
    "        results.loc[i, 'Acceptance Probability'] = accept_prob\n",
    "        results.loc[i, 'Random Number'] = rnd\n",
    "        results.loc[i, 'Outcome'] = outcome\n",
    "\n",
    "        # Temperature cooling schedule\n",
    "        if i % update_iters == 0:\n",
    "            if temp_reduction == 'geometric':\n",
    "                T = alpha * T\n",
    "            elif temp_reduction == 'linear':\n",
    "                T -= alpha\n",
    "            elif temp_reduction == 'slow decrease':\n",
    "                b = 5 # Arbitrary constant\n",
    "                T = T / (1 + b * T)\n",
    "            else:\n",
    "                raise Exception(\"Temperature reduction strategy not recognized\")\n",
    "\n",
    "    # Convert column indices of best subset to original names\n",
    "    best_subset_cols = [list(X_train.columns)[i] for i in list(best_subset)]\n",
    "\n",
    "    # Drop NaN rows in results\n",
    "    results = results.dropna(axis=0, how='all')\n",
    "\n",
    "    # Save results as CSV\n",
    "    dt_string = dt.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results.to_csv(\"results.csv\", index=False)\n",
    "\n",
    "    return results, best_metric, best_subset_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/train_data.csv\", index_col=0)\n",
    "\n",
    "df = df.dropna()\n",
    "df = pd.get_dummies(df, columns = [\"to_be_predicted\"])\n",
    "\n",
    "df['a'] = pd.to_datetime(df['a']).astype('int64')\n",
    "df['b'] = pd.to_datetime(df['b']).astype('int64')\n",
    "df['c'] = pd.to_datetime(df['c']).astype('int64')\n",
    "\n",
    "X = df.drop(\"prediction_columns\", axis=1)\n",
    "X = df.select_dtypes(include=[int,float])\n",
    "y = df[[\"to_be_predicted\"]]\n",
    "\n",
    "\n",
    "simulated_annealing(X, y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
